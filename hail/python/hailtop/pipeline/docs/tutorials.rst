.. _sec-tutorial:

========
Tutorial
========

This tutorial goes through the basic concepts of Pipeline with examples.


Overview
--------

A :class:`.Pipeline` consists of a set of :class:`.Task`s to execute. There can be
an arbitrary number of tasks in the pipeline that are executed in order of their dependencies.
A dependency between two tasks states that the dependent task should not run until
the previous task completes. Thus, under the covers a pipeline is a directed acyclic graph (DAG)
of tasks.

# Image here of an example of a DAG

Import
------

Pipeline is located inside the `hailtop` module, which can be installed
as described in the :ref:`Getting Started <sec-getting_started>` section.

.. code-block:: python

    >>> import hailtop.pipeline as hp


.. _f-strings:

f-strings
---------

f-strings were added to Python in version 3.6 and are denoted by the 'f' character
before a string literal. When creating the string, Python evaluates any expressions
in single curly braces `{...}` using the current variable scope. When Python compiles
the example below, the string 'Alice' is substituted for `{name}` because the variable
`name` is set to 'Alice' in the line above.

.. code-block:: python

    >>> name = 'Alice'
    >>> print(f'hello {name}')
    'hello Alice'

You can put any arbitrary Python code inside the curly braces and Python will evaluate
the expression correctly. For example, below we evaluate `x + 1` first before compiling
the string. Therefore, we get 'x = 6' as the resulting string.

.. code-block:: python

    >>> x = 5
    >>> print(f'x = {x + 1}')
    'x = 6'

To use an f-string and output a single curly brace in the output string, escape the curly
brace by duplicating the character. For example, `{` becomes `{{` in the string definition,
but will print as `{`. Likewise, `}` becomes `}}`, but will print as `}`.

.. code-block:: python

    >>> x = 5
    >>> print(f'x = {{x + 1}} plus {x}')
    'x = {x + 1} plus 5'

To learn more about f-strings, check out this `tutorial <https://www.datacamp.com/community/tutorials/f-string-formatting-in-python>`_.

Hello World
-----------

In the example below, we have defined a :class:`.Pipeline` `p` with the name 'hello'.
We use the method :meth:`.Pipeline.new_task` to create a task object which we call `t` and then
use the method :meth:`.Task.command` to tell Pipeline that we want to execute `echo "hello world"`.
However, at this point, Pipeline hasn't actually run the task to print "hello world". All we have
done is specified the tasks and the order in which they should be run. To actually execute the
Pipeline, we call :meth:`.Pipeline.run`. The `name` arguments to both :class:`.Pipeline` and
:class:`.Task` are used in the :ref:`Batch Service UI <batch-service>`.

.. code-block:: python

    >>> p = hp.Pipeline(name='hello')
    >>> t = p.new_task(name='t1')
    >>> t.command('echo "hello world"')
    >>> p.run()


Now that we know how to create a pipeline with a single task, we call :meth:`.Pipeline.new_task`
twice to create two tasks `s` and `t` which both will print a variant of hello world to stdout.
Calling `p.run()` executes the pipeline. By default, pipelines are executed by the :class:`.LocalBackend`
which runs tasks on your local computer. Therefore, even though these tasks can be run in parallel,
they are still run sequentially. However, if pipelines are executed by the :class:`.BatchBackend`
using the :ref:`Batch Service <sec-batch_service>`, then `s` and `t` can be run in parallel as
there exist no dependencies between them.

.. code-block:: python

    >>> p = hp.Pipeline(name='hello-parallel')
    >>> s = p.new_task(name='t1')
    >>> s.command('echo "hello world 1"')
    >>> t = p.new_task(name='t2')
    >>> t.command('echo "hello world 2"')
    >>> p.run()

To create a dependency between `s` and `t`, we use the method :class:`.Task.depends_on` to
explicitly state that `t` depends on `s`. In both the :class:`.LocalBackend` and
:class:`.BatchBackend`, `s` will always run before `t`.

.. code-block:: python

    >>> p = hp.Pipeline(name='hello-serial')
    >>> s = p.new_task(name='t1')
    >>> s.command('echo "hello world 1"')
    >>> t = p.new_task(name='t2')
    >>> t.command('echo "hello world 2"')
    >>> t.depends_on(s)
    >>> p.run()


File Dependencies
-----------------

So far we have created pipelines with two tasks where the dependencies between
them were stated explicitly. However, in many pipelines, we want to have a file
generated by one task be the input to a downstream task. Pipeline has a mechanism
for tracking file outputs and then inferring task dependencies from the usage of
those files.

In the example below, we have specified two tasks `s` and `t`. `s` prints
"hello world" as in previous examples. However, instead of printing to stdout,
this time `s` redirects the output to a temporary file defined by `s.ofile`.
`s.ofile` is a Python object of type :class:`.TaskResourceFile` that was created
on the fly when we used any attribute of a :class:`.Task` for the first time.
Then any time we access the attribute again (in this case `s.ofile`),
we get the same :class:`.TaskResourceFile` that was previously created.

Note the 'f' character before the string! We placed `s.ofile` in curly braces so
when Python interpolates the :ref:`f-string <f-string>`, it replaced the
:class:`.TaskResourceFile` object with an actual file path into the command for `s`.
We use another f-string in `t`'s command where we print the contents of `s.ofile` to stdout.
`s.ofile` is the same temporary file that was created in the command for `t`. Therefore,
pipeline deduces that `t` must depend on `s` and thus creates



.. code-block:: python

    >>> p = hp.Pipeline(name='hello-serial')
    >>> s = p.new_task(name='t1')
    >>> s.command(f'echo "hello world" > {s.ofile}')
    >>> t = p.new_task(name='t2')
    >>> t.command(f'cat {s.ofile}')
    >>> p.run()


Scatter / Gather
----------------

.. code-block:: python

    >>> p = hp.Pipeline(name='scatter')
    >>> for name in ['Alice', 'Bob', 'Dan']:
    ...     t = p.new_task(name=name)
    ...     t.command(f'echo "hello {name}"')
    >>> p.run()


.. code-block:: python

    >>> p = hp.Pipeline(name='scatter-gather-1')
    >>> tasks = []
    >>> for name in ['Alice', 'Bob', 'Dan']:
    ...     t = p.new_task(name=name)
    ...     t.command(f'echo "hello {name}"')
    ...     tasks.append(t)
    >>> sink = p.new_task(name='sink')
    >>> sink.depends_on(*tasks)
    >>> p.run()


.. code-block:: python

    >>> p = hp.Pipeline(name='scatter-gather-2')
    >>> tasks = []
    >>> for name in ['Alice', 'Bob', 'Dan']:
    ...     t = p.new_task(name=name)
    ...     t.command(f'echo "hello {name}" > {t.ofile}')
    ...     tasks.append(t)
    >>> sink = p.new_task(name='sink')
    >>> sink.command('cat {}'.format(' '.join([t.ofile for t in tasks]))
    >>> p.run()


Nested Scatters
---------------

.. code-block:: python

    >>> def do_chores(p, user):
    ...     make_bed = p.new_task(name=f'{user}-make-bed',
    ...                           attributes={'user': user})
    ...     laundry = p.new_task(name=f'{user}-laundry',
    ...                          attributes={'user': user})
    ...     grocery_shop = p.new_task(name=f'{user}-grocery-shop',
    ...                               attributes={'user': user})
    ...     grocery_shop.depends_on(make_bed, laundry)
    ...     return grocery_shop

    >>> p = hp.Pipeline(name='nested-scatter')
    >>> user_chores = [do_chores(p, user)
    ...                for user in ['Alice', 'Bob', 'Dan']]
    >>> all_done = p.new_task(name='sink')
    >>> all_done.depends_on(*user_chores)
    >>> p.run()


Input Files
-----------

.. code-block:: python

    >>> p = hp.Pipeline(name='hello-input')
    >>> input = p.read_input('data/hello.txt')
    >>> t = p.new_task(name='hello')
    >>> t.command('cat {input}')
    >>> p.run()


Output Files
------------

.. code-block:: python

    >>> p = hp.Pipeline(name='hello-input')
    >>> t = p.new_task(name='hello')
    >>> t.command('echo "hello" > {t.ofile}')
    >>> p.write_output(t.ofile, 'output/hello.txt')
    >>> p.run()


Resource Groups
---------------

.. code-block:: python

    >>> p = hp.Pipeline(name='resource-groups')
    >>> bfile = p.read_input_group(bed='data/example.bed',
    ...                            bim='data/example.bim',
    ...                            fam='data/example.fam')
    >>> wc_bim = p.new_task(name='wc-bim')
    >>> wc_bim.command(f'wc -l {bfile.bim}')
    >>> wc_fam = p.new_task(name='wc-fam')
    >>> wc_fam.command(f'wc -l {bfile.fam}')
    >>> p.run()


.. code-block:: python

    >>> p = hp.Pipeline(name='resource-groups')
    >>> create = p.new_task(name='create-dummy')
    >>> create.declare_resource_group(bfile={'bed': '{root}.bed',
    ...                                      'bim': '{root}.bim',
    ...                                      'fam': '{root}.fam'}
    >>> create.command(f'plink --dummy 10 100 --make-bed --out {create.bfile}')
    >>> p.run()
